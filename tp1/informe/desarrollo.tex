Existen múltiples formas en las que se puede resolver algorítmicamente un sistema de ecuaciones lineales como el nuestro, del tipo $C r = b$. Con distintas complejidades al implementar y distintas características, entre ellas se encuentran:

\begin{itemize}
    \item \textbf{Eliminación Gaussiana sin pivoteo}: Este es uno de los métodos métodos más sencillos desde el punto de vista teórico. Consiste en derivar un sistema como el nuestro en un sistema con una matriz triangular para que sea fácil de resolver. Como ventaja: es de fácil implementación; como desventaja: no todos los sistemas pueden resolverse mediante Eliminación Gaussiana sin pivoteo y es susceptible a errores numéricos. Entre otras cosas, consta con una complejidad de $O(n^3)$.
    \item \textbf{Factorización LU}: Esencialmente se apoya en el método anterior. Consiste en obtener una factorización $C = LU$ donde $L$ es triangular inferior con unos en la diagonal y $U$ es triangular superior. Como ventaja respecto a la Eliminación Gaussiana sin pivoteo es que mediante la resolución de dos sistemas de ecuaciones simples se puede lograr una complejidad de $O(n^2)$. Como desventaja: aún no todos los sistemas pueden resolverse utilizando este método.
    \item \textbf{Factorización de Cholesky}: Consiste en encontrar una factorización $C = LL^t$ donde $L$ es una matriz triangular inferior. Una vez se obtiene la factorización se puede resolver el sistema en cuestión utilizando, al igual que antes, dos sistemas intermedios. La diferencia con los métodos previos es que hay un algoritmo que permite hallar las matrices de estos sistemas sin Eliminación Gaussiana. Como ventaja: es más eficiente para representar sistemas de ecuaciones en memoria y cuenta con una complejidad de $O(n^2)$ aunque con mejores constantes que el Método de Factorización LU. Por otra parte, tiene una mayor estabilidad numérica. Como desventaja: no todos los sistemas pueden resolverse mediante este método, sólo aquellos cuya matriz principal sea \textit{simétrica definida positiva}.
\end{itemize}

Todos los métodos se complementan con el algoritmo de \textit{backward substitution} ($O(n^2)$) para resolver el sistema.

\subsection{Elección del algoritmo}

Nos fue requerido resolver el sistema mediante Eliminación Gaussiana sin pivoteo (EG). Observemos que como la matriz $C$ de nuestro sistema es simétrica definida positiva \cite{CMMpaper} cumple con las condiciones para resolverse con cualquiera de los métodos mencionados.

\subsection{Algunas características de nuestro sistema}

Para ello, analicemos primero cómo es la matriz $C$ de nuestro sistema y por qué cumple con las condiciones para resolverse mediante el método mencionado.

\begin{itemize}
    \item \textbf{De tener solución, es única}: dado que contamos con $n = \#\{equipo\}$ ecuaciones y $n = dim(r)$ incógnitas.
    \item \textbf{Es simétrica}: ya que la cantidad de partidos jugados entre el equipo $i$ y el equipo $j$ es la cantidad de partidos jugados por el equipo $j$ e $i$.
    \item \textbf{Es estrictamente diagonal dominante}: Por definición $n_i = \sum_{j \neq i} n_{i, j}$, por lo que es claro que $|C_{i, i}| > \sum_{j \neq i}|C_{i, j}|$ ya que $C_{i, i} = 2 + n_i$.
\end{itemize}

Al ser $C$ estrictamente diagonal dominante tiene, entre otras, las siguientes propiedades:

\begin{itemize}
    \item Es no singular
    \item Sus submatrices principales también son estrictamente diagonal dominantes
\end{itemize}

Por otro lado, sabemos que si las submatrices principales de una matriz son no singulares, entonces la misma tiene factorización LU, lo que implica la correcta aplicación de la Eliminación Gaussiana sin pivoteo.

Se implica directamente que a \textbf{$C$ se le puede aplicar la Eliminación Gaussiana sin pivoteo}.

\subsection{Sobre la estabilidad numérica de la Eliminación Gaussiana sin pivoteo}\label{estabilidad_numerica}

La aritmética finita de las computadoras traen aparejados problemas para representar nuestro sistema numérico. En el caso de la Eliminación Gaussiana sin pivoteo podría presentarse al realizar una división por algún elemento de la diagonal de la matriz en cuestión que esté muy cercano a cero. En tal caso cualquier error se vería amplificado. No obstante el ser $C$ una matriz estrictamente diagonal dominante y simétrica nos asegura tener en la diagonal el elemento más grande en módulo tanto por fila como por columna, por lo que el pivoteo parcial en un caso como este sería redundante y se logra una cierta estabilidad numérica.

No obstante, las pruebas de control sobre la implementación acotan el error por $10^{-4}$.

\subsection{Sobre WP y Elo}

Como comentamos en la introducción, WP es una de las razones por las que CMM existe. No obstante, Elo fue creado de forma independiente y hoy es utilizado considerablemente en el ajedrez competitivo y se ha extendido a otras ramas de actividades.

Aunque a nivel implementativo no son muy interesantes en este trabajo, si vamos a ahondar en la cuestión cualitativa de ambos para compararlos con CMM \ref{cmm_comparacion}.