
\subsection{Búsqueda de parámetros óptimos }

El principal objetivo de esta sección es encontrar los parámetros óptimos de knn y knn+pca con respecto a la accuracy. 

\subsection{Experimentación preliminar}
Este primer segmento de la sección se enfoca en generar una intuición sobre cómo reaccionan los métodos frente a distintos valores de $\alpha$, $k$ para ello utilizamos una partición del dataset original para poder experimentar sobre un rango bastante extenso de parámetros sin preocuparnos demasiado por la complejidad. Este primer experimento consiste en utilizar un split simple de train y validación sobre la partición previamente elegida para cada k en el caso de kNN y para cada pareja $\alpha$, $k$ en caso de kNN+PCA. 


\paragraph{kNN}
.
\begin{figure}[h]
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.9\linewidth, height=5cm]{images/validacionSimple_knnsolo.png} 
\caption{Rango de 1-300 con granularidad 10}
\label{fig:subimbar_medio1}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.9\linewidth, height=5cm]{images/validacionSimple_knnsolo_Kchicos.png} 
\caption{Rango de 1-30 con granularidad 1}
\label{fig:subimbar_medio2}
\end{subfigure}
\caption{Validación Simple de kNN sobre el dataset reducido.}
\label{knn_preliminar}%
\end{figure}

\par

En la imagen \ref{fig:subimbar_medio1} se puede observar una relación inversamente proporcional entre el k elegido y su accuracy, para vislumbrar si esto es así realizamos el mismo experimento sobre valores pequeños de k pero ahora con más granularidad para notar cualquier variación en el accuracy (imagen \ref{fig:subimbar_medio2}). Ahora con más detalle se puede ver a partir de cuales magnitudes el método disminuye se eficiencia, en particular los mejores k parecen encontrarse dentro del rango 1-15.

\paragraph{kNN+PCA}
.
\par 
\begin{figure}[H]
    \centering
    \includegraphics[width=12cm]{images/validacionSimple_heatmap_datasetRedux}%
    \qquad
    \caption{Validación Simple de kNN+PCA sobre el dataset reducido}
    \label{knnpca_preliminar}%
\end{figure}

Al igual que sucede en kNN podemos notar un mejor desempeño para las parejas con valores chicos de $k$, en cambio para $\alpha$ ya no está clara la relación aunque se puede ver una leve mejora para los $\alpha$ menores a 100, por esto mismo en el experimento siguiente mantendremos el rango del $\alpha$ y solo achicaremos el de $k$.

\subsection{Validación Simple sobre el dataset completo}

La segunda parte de esta sección realiza el mismo experimento que la primera pero ahora sobre el dataset original y eligiendo un rango condicionado por lo antes visto, con la motivación de encontrar el conjunto de los mejores diez predictores para cada método. Nótese que cuando decimos que el rango del experimento actual estará condicionado por una experimentación realizada sobre un dataset reducido ,estamos asumiendo que los parámetros óptimos se ven inmutables por la cantidad de datos para entrenar y validar lo cual no es trivial por esa razón lo analizamos en la sección \ref{fer}.


\paragraph{kNN}
.
\begin{itemize}

    \item \textbf{Rango de $k$}: $\{1\dots30, 1\}$


\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=8cm]{images/validacionSimple_datasetCompleto.png}%
    \qquad
    \caption{Validación Simple de kNN sobre el dataset completo}
    \label{knn_valSimple}%
\end{figure}

\begin{table}[h!]
    \begin{center}
        \begin{tabular}{|c|c|}
        \hline
        \textbf{$k$} & \textbf{accuracy} \\
        \hline
        3 &  0.9711\\
        4 & 0.9703\\
        5 & 0.9696\\
        6 & 0.9695\\
        7 &  0.9689\\
        8 & 0.9686\\
        1 & 0.9675\\
        10 & 0.9675\\
        9 & 0.9670\\
        11 & 0.9657\\
        
        \hline
        \end{tabular}
        \caption{Accuracy de las mejores 10 parejas extraído de la Validación Simple sobre el dataset completo para kNN.}
        \label{knn_valSimple_table}
    \end{center}
\end{table}

\paragraph{kNN+PCA}.

\par
\begin{itemize}

    \item \textbf{Rango de $k$}: $\{1\dots80, 2\}$
    \item \textbf{Rango de $\alpha$}: $\{1\dots160, 5\}$

\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=12cm]{images/validacionSimple_datasetCompleto_knnpca_k80}%
    \qquad
    \caption{Validación Simple de kNN+PCA sobre el dataset completo}
    \label{knnpca_valSimpleCompleto}%
\end{figure}


\begin{table}[h!]
    \begin{center}
        \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{$k$} & \textbf{$\alpha$} & \textbf{accuracy} \\
        \hline
        50 & 6 & 0.9736\\
        50 & 4 & 0.9734\\
        55 & 6 & 0.9733\\
        40 & 6 & 0.9739\\
        35 & 6 & 0.9728\\
        45 & 4 & 0.9728\\
        35 & 8 & 0.9726\\
        75 & 6 & 0.9726\\
        55 & 4 & 0.9726\\
        45 & 6 & 0.9723\\
        
        \hline
        \end{tabular}
        \caption{Accuracy de las mejores 10 parejas extraído de la Validación Simple sobre el dataset completo para kNN+PCA.}
        \label{knnpca_valSimple_table}
    \end{center}
\end{table}

\subsubsection{Validación Cruzada}

Por último para conseguir el mejor parámetro o la mejor pareja en el caso de kNN+PCA se somete a los predictores obtenidos en el segmento previo a 10-fold cross
validation para evitar cualquier tipo de sesgo que pudiera tener nuestro anterior split de entrenamiento y validación. La misma se realiza sobre una partición del 80 $\%$ del dataset dejando el restante para testear ambos métodos.
El funcionamiento de la validación cruzada junto a la elección de 10 como cantidad de particiones en las que se dividirá el set de entrenamiento se detalla en la sección \ref{crossvalidationkfold}.

\paragraph{kNN}.

\begin{itemize}
    \item \textbf{$k$}: $ \{1,3,4,5,6,7,8,9,10,11\}$
\end{itemize}
\begin{table}[h!]
    \begin{center}
        \begin{tabular}{|c|c|}
        \hline
        \textbf{$k$} & \textbf{accuracy} \\
        \hline
        3 &  0.9671\\
        5 & 0.9668\\
        4 & 0.9664\\
        6 & 0.9656\\
        1 &  0.9654\\
        7 & 0.9653\\
        8 & 0.9640\\
        9 & 0.9633\\
        10 & 0.9629\\
        11 & 0.9623\\
        
        \hline
        \end{tabular}
        \caption{Accuracy promedio resultante de la Validación Cruzada para kNN.}
        \label{knn_crossVal_table}
    \end{center}
\end{table}

\paragraph{kNN+PCA}.

En el caso de kNN+PCA  no solo tomamos las diez mejores parejas resultantes de la validación simple si no que extraemos los $\alpha$, $k$ de ellas y sometemos a validación cruzada a la combinación de todos esos parámetros.

\begin{itemize}
    \item \textbf{$k$}: $ \{4,6,8\}$
    \item \textbf{$\alpha$}: $\{  35, 40, 45, 50, 55, 75 \}$
\end{itemize}

\begin{table}[h!]
    \begin{center}
        \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{$k$} & \textbf{$\alpha$} & \textbf{accuracy} \\
        \hline
        40 & 4 & 0.9716\\
        35 & 6 & 0.9713\\
        40 & 6 & 0.9712\\
        35 & 4 & 0.9712\\
        45 & 6 & 0.9711\\
        45 & 4 & 0.9711\\
        50 & 4 & 0.9710\\
        40 & 8 & 0.9710\\
        35 & 8 & 0.9710\\
        55 & 6 & 0.9708\\
        
        \hline
        \end{tabular}
        \caption{Accuracy de las mejores 10 parejas de Validación Cruzada para kNN+PCA .}
        \label{knnpca_crossVal_table}

    \end{center}
\end{table}

\subsubsection{ Testing sobre el mejor predictor : }

Testeamos el mejor predictor sobre el el 20$\%$ del dataset previamente separado.
\paragraph{kNN}.
\par 
\vspace{0.5cm}
$Accuracy = 0.9661 $
\par
\vspace{0.5cm}
Aclaración : La matriz de Confusión tiene ceros en la diagonal para favorecer la visualización de las demás casillas.
\begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{images/ConfMatrix_knn.png}%
    \qquad
    \caption{Matriz de Confusión para el mejor parámetro de kNN }
    \label{knn_MatrizConf}%
\end{figure}



\begin{figure}[H]
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.9\linewidth, height=5cm]{images/recall_knn.png} 
\caption{Recall del mejor parámetro}
\label{knn_métricas1}%
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.9\linewidth, height=5cm]{images/precision_knn.png} 
\caption{Precision del mejor parámetro}
\label{knn_métricas2}%
\end{subfigure}
\caption{Métricas del mejor parámetros para kNN.}
\label{knn_métricas}%
\end{figure}


Se puede observar en \ref{knn_métricas1} que la cantidad de datos relevantes que se recuperan del set de validación no es el mismo para cada dígito, la diferencia se aprecia claramente cuando comparamos el $0$ o el $1$ con el $8$ , en los primeros solo alrededor de un $1\%$ no es relevante , en cambio con este último aproximadamente un  $7\%$ .

En contraste si observamos \ref{knn_métricas1} para estos mismos dígitos se invierten los roles, podemos ver que la cantidad de dígitos recuperados como $8$ son relevantes.
Lo que sucede es que muchos datos de esta clase están siendo confundidos con otras, en \ref{knn_MatrizConf} se puede notar esto.
\paragraph{kNN+PCA}.


\vspace{0.5cm}
$Accuracy = 0.9725 $
\par
\vspace{0.5cm}
Aclaración : La matriz de Confusión tiene ceros en la diagonal para favorecer la visualización de las demás casillas.

\begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{images/ConfMatrix_knnpca.png}%
    \qquad
    \caption{Matriz de Confusión para el mejor parámetro de kNN }
    \label{knnpca_MatrizConf}%
\end{figure}

\begin{figure}[h]
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.9\linewidth, height=5cm]{images/recall_knnpca.png} 
\caption{Recall de la mejor pareja}
\label{fig:metpca1}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=0.9\linewidth, height=5cm]{images/precision_knnpca.png} 
\caption{Precision de la mejor pareja}
\label{fig:metpca2}
\end{subfigure}
\caption{Métricas de la mejor pareja para kNN+PCA.}
\label{knnpca_metricas}%
\end{figure}

En \ref{fig:knnpca_metricas} comparando ambas métricas podemos notar que con el $3$ sucede algo similar a lo que pasaba con el $8$ en el dataset no transformado.

En particular si observamos el $9$ sucede totalmente lo contrario casi todos los datos del set de validación relevantes son recuperados (recall alta) , pero a su vez muchos de esos recuperados no son relevantes (precision baja).




\subsubsection{Conclusión de los parámetros óptimos}


Como expresamos anteriormente para algunos dígitos estos métodos funcionan casi perfectamente pero para otros su rendimiento decrece. Estas disparidades en la predicción hacen que nos planteemos algunas dudas , si estos datos mal clasificados pueden  considerarse como outliers dado a que su morfología no se asemeja al dígito que dice su etiqueta en ese caso se podría pensar que estos errores no son muy graves. De lo contrario si esto no sucede en la mayoría de los casos tal vez debamos modificar nuestro entrenamiento si queremos mejorar la predicción de alguna de estas clases complicadas.

%al vez el 
%como por ejemplo tal vez con alguna elección de  parámetros en las que baje un poco el accuracy general podríamos lograr un desempeño mejor en algunos de estos dígitos complicados, otra posibilidad sería que necesitamos más datos de esos dígitos para entrenar el método y así balancear el rendimiento de todas las clases.
%Tal vez
