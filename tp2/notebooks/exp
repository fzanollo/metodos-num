#!/usr/bin/env python3

import sys
sys.path.insert(0, '..') # incluir modulos de la parent folder
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, recall_score, f1_score, cohen_kappa_score, precision_score
from textwrap import dedent
import numpy as np
import pandas as pd
import math
import metnum
import time
import os


kNN_ks = [i for i in range(1,53,2)] 
kNN_k_max = kNN_ks[-1]
alphas = [i for i in range(10,120,10)]
alpha_max = alphas[-1]


def pca(alpha, X_train, X_test):
    pca = metnum.PCA(alpha)
    pca.fit(X_train)
    return pca.transform(X_train), pca.transform(X_test)

def work(X, y, n_kfold):

    data = []

    kf = KFold(n_splits=n_kfold)
    i = 1
    for train_index, test_index in kf.split(X):
        print(f"{os.getpid()} kfold {i}/{n_kfold}")

        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y[train_index], y[test_index]

        print(dedent(
        f"""
        {os.getpid()} Calculando la matriz PCA para el alpha maximo = {alpha_max}
        """
        ))
        
        X_train_pca_max, X_test_pca_max = pca(alpha_max, X_train,X_test)

        for alpha in alphas :
            X_train_pca, X_test_pca = X_train_pca_max[0:, 0:alpha], X_test_pca_max[0:, 0:alpha]
            
            print(dedent(
            f"""
            {os.getpid()} Entrenando kNN para el k maximo = {kNN_k_max}
            """
            ))
            
            clf = metnum.KNNClassifier(kNN_k_max)
            clf.fit(X_train_pca, y_train)
            clf.load(X_test_pca)
            
            for k in kNN_ks :
                
                print(dedent(
                f"""
                    {os.getpid()} Pruebas para kNN+PCA
                    
                    {os.getpid()} train set de {X_train.shape[0]} elementos
                    {os.getpid()} knn={k}
                    {os.getpid()} alpha={alpha}
                    {os.getpid()} kfold={n_kfold}                    
                """
                ))
                
                y_pred = clf.predict(k)

                data.append({
                    "train_size": X.shape[0],
                    "knn": k,
                    "alpha": alpha,
                    "kfold": n_kfold,
                    "accuracy": accuracy_score(y_test, y_pred),
                    "recall": recall_score(y_test, y_pred, average = 'weighted'),
                    "f1": f1_score(y_test, y_pred, average = 'weighted'),
                    "cohen_kappa": cohen_kappa_score(y_test, y_pred),
                    "precision": precision_score(y_test, y_pred, average = 'weighted'),
                })

        i += 1
        
    return data


def makePartitionAndWork(X, y, n_kfold, partition_size=200):
    
    accumulator = 0
    i = 1

    parts = math.ceil(X.shape[0] / partition_size)

    while True:
        part_X = X.head(accumulator + partition_size)
        part_y = y.head(accumulator + partition_size)
        
        print(dedent(
        f"""
            {os.getpid()} train size: {part_X.shape[0]}
            {os.getpid()} partición: {i}/{parts}
        """
        ))

        filename = f"knn_pca_results/result_{part_X.shape[0]}_{n_kfold}.csv"
     
        data = work(part_X, part_y, n_kfold)
        result = pd.DataFrame(data)

        result.to_csv(filename, index=False)       
        
        print(dedent(
        f"""
            {os.getpid()} Resultados escritos a {filename}
        """
        ))
        
        accumulator += partition_size        
        
        i += 1
        if accumulator >= X.shape[0]:
            break
    

def main(
    universe_size:("tamaño a tomar del dataset original para hacer las pruebas [5000]")=5000,
    partition_size:("tamaño de partición para hacer una prueba incremental [4000]")=math.ceil(5000*0.8),
    kfold:("parámetro de kfold [10]")=10,
    train_set_proportion:("relación de tamaño de trainset vs testset [0.8]")=0.8
    ):
    "Pruebas para kNN + PCA"

    print(dedent(
    f"""
        {os.getpid()} Pruebas para kNN+PCA

        {os.getpid()} universe_size={universe_size}
        {os.getpid()} train_set_proportion={train_set_proportion}
        {os.getpid()} partition_size={partition_size}
    """
    ))
    
    assert universe_size * train_set_proportion >= partition_size
    
    df_train = pd.read_csv("../../data/train.csv")
    df_train = df_train[:universe_size]
    X = df_train[df_train.columns[1:]]
    y = df_train["label"]

    limit = int(train_set_proportion * X.shape[0]) 

    X_train, y_train = X[:limit], y[:limit]

    assert len(X_train) == len(y_train)
    
    makePartitionAndWork(X_train, y_train, kfold, partition_size)
    
    


if __name__ == '__main__':
    import plac; plac.call(main)