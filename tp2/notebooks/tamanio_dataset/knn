#!/usr/bin/env python3

import sys
sys.path.insert(0, '..') # incluir modulos de la parent folder
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, recall_score, f1_score, cohen_kappa_score, precision_score
from textwrap import dedent
import numpy as np
import pandas as pd
import math
import metnum
import time
import os

def work(X, y, clf, n_knn, n_kfold):

    data = []

    kf = KFold(n_splits=n_kfold)
    i = 1
    for train_index, test_index in kf.split(X):
        print(f"{os.getpid()} kfold {i}/{n_kfold}")

        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y[train_index], y[test_index]

        clf.fit(X_train, y_train)
        begin = time.time()
        y_pred = clf.predict(X_test)
        end = time.time()

        data.append({
            "train_size": X.shape[0],
            "knn": n_knn,
            "kfold": n_kfold,
            "accuracy": accuracy_score(y_test, y_pred),
            "recall": recall_score(y_test, y_pred, average = 'weighted'),
            "f1": f1_score(y_test, y_pred, average = 'weighted'),
            "cohen_kappa": cohen_kappa_score(y_test, y_pred),
            "precision": precision_score(y_test, y_pred, average = 'weighted'),
            "predict_time": (end - begin)
        })

        i += 1

    return data

def makePartitionAndWork(X, y, n_knn, n_kfold, partition_size=200):

    result = pd.DataFrame()

    accumulator = 0
    i = 1

    parts = math.ceil(X.shape[0] / partition_size)

    clf = metnum.KNNClassifier(n_knn)

    while True:
        part_X = X.head(accumulator + partition_size)
        part_y = y.head(accumulator + partition_size)

        print(dedent(
        f"""
            {os.getpid()} train size: {part_X.shape[0]}
            {os.getpid()} partición: {i}/{parts}
        """
        ))

        data = work(part_X, part_y, clf, n_knn, n_kfold)

        result = pd.concat([result, pd.DataFrame(data)])

        accumulator += partition_size

        i += 1
        if accumulator >= X.shape[0]:
            break

    return result

def main(
    universe_size:("tamaño a tomar del dataset original para hacer las pruebas [5000]")=5000,
    partition_size:("tamaño de partición para hacer una prueba incremental [4000]")=math.ceil(5000*0.8),
    knn:("parámetro de knn [10]")=10,
    kfold:("parámetro de kfold [10]")=10,
    train_set_proportion:("relación de tamaño de trainset vs testset [0.8]")=0.8
    ):
    "Pruebas para Knn"

    assert universe_size * train_set_proportion >= partition_size

    filename = f"knn_results/result_{universe_size}_{partition_size}_{knn}_{kfold}_{train_set_proportion}.csv"

    df_train = pd.read_csv("../../data/train.csv")
    df_train = df_train[:universe_size]
    X = df_train[df_train.columns[1:]]
    y = df_train["label"]

    limit = int(train_set_proportion * X.shape[0]) 

    X_train, y_train = X[:limit], y[:limit]

    assert len(X_train) == len(y_train)

    print(dedent(
    f"""
        {os.getpid()} Pruebas para Knn

        {os.getpid()} filename={filename}
        {os.getpid()} universe_size={universe_size}
        {os.getpid()} train_set_proportion={train_set_proportion}
        {os.getpid()} partition_size={partition_size}
        {os.getpid()} knn={knn}
        {os.getpid()} kfold={kfold}

        {os.getpid()} train set final de {X_train.shape[0]} elementos
    """
    ))

    begin = time.time()
    result = makePartitionAndWork(X_train, y_train, knn, kfold, partition_size)
    end = time.time()

    result.to_csv(filename, index=False)

    print(f"{os.getpid()} duration: {end - begin}")

    exit(0)


if __name__ == '__main__':
    import plac; plac.call(main)